很好的延伸問題 👌，因為 AI 能做 ≠ AI 做得好。目前（2025 年）LLM 與 AI 工具在軟體開發的不同階段有明顯的強弱差異，可以這樣劃分：

⸻

✅ 目前比較擅長的 (AI 已經能大幅提升效率)

1. 程式碼相關
	•	程式碼生成 / 補全 (Coding Copilot)
→ 產生樣板程式、CRUD API、常見演算法、正則表達式
	•	程式碼解釋 / 文件化
→ 讀懂陌生程式碼、產生註解或 API doc
	•	程式碼轉換 / 重構建議
→ 語言轉換 (例如 Python → Go)、舊程式清理、風格一致化
	•	單元測試生成
→ 自動寫出常見的 test case，mock 基本可用

2. 文本與知識處理
	•	需求文件 → 初步設計/任務拆解
→ 從一段需求文字產生 ERD、API 規劃、分工清單
	•	文件自動生成
→ 自動產生 README、技術文件、release note
	•	Q&A 搜索
→ 在大型 codebase 或 API doc 中找答案

3. 專案與溝通
	•	會議紀錄摘要 / Action items
	•	工單拆解 (JIRA/Trello)
	•	簡單進度預測（根據 PR / commit 數據）

⸻

⚠️ 目前能做，但效果有限 (需要人審核或輔助)

1. 測試
	•	測試覆蓋率建議
→ 能找到部分漏測路徑，但對複雜邏輯容易 miss
	•	Bug 定位 / 修復建議
→ AI 能從 log/stack trace 給提示，但「修正是否正確」要工程師確認

2. 架構設計
	•	架構圖 / API 設計建議
→ 可以快速給 draft，但不一定符合性能/擴展性/團隊需求
	•	技術選型
→ 能給出常見選項，但對 成本、維運、團隊熟悉度 不會真正考慮

3. DevOps
	•	CI/CD pipeline 改善建議
→ 能看出 log 問題，但缺乏對公司 Infra 的上下文理解
	•	IaC (Terraform/K8s yaml) 自動生成
→ 初稿可用，但要人工調整參數/最佳化

⸻

❌ 目前比較不擅長的 (AI 還不太可靠)

1. 深度系統設計 & 架構決策
	•	對 高併發、低延遲、分散式系統 trade-off 的取捨不足
	•	無法完全取代架構師在 非功能性需求 (效能、容錯、成本、安全) 上的判斷

2. 安全 (AppSec)
	•	靠 AI 自動做滲透測試或找 0-day 目前可靠性低
	•	靠 AI 自動修安全漏洞風險很大（可能修錯方向）

3. 大型專案進度管理
	•	雖然能拆分任務，但難以評估 團隊人力、優先順序、跨部門依賴
	•	預測延遲的準確度目前不高

4. 維運與 Incident Response
	•	AI 可以幫忙分析 log，但在 跨系統複雜故障 的場合往往給出錯誤建議
	•	需要 SRE/DevOps 專家進行判斷

⸻

總結
	•	目前 AI 最擅長：
	•	程式碼層面（生成、補全、轉換、測試）
	•	文件/知識管理（文件生成、Q&A、需求→設計雛型）
	•	可用但需審核：
	•	測試覆蓋率、Bug 定位、架構圖、CI/CD 自動化
	•	仍不擅長：
	•	深度系統設計、安全分析、大型專案管理、複雜 Incident Handling

⸻

要不要我幫你做一個 「雷達圖 / 強弱分布圖」，一眼就能看出 AI 在各開發環節的能力強弱？
